{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from utils import PathsData, import_data, split_data, plot_correlation\n",
    "from features import FeaturesFrame\n",
    "from models import Model, ModelEnum, ParamGridEnum\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "# from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "x_validation = import_data(PathsData.X_TEST.value) #! to use in the end to make a submission\n",
    "x = import_data(PathsData.X_TRAIN.value)\n",
    "y = import_data(PathsData.Y_TRAIN.value)\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x=x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = FeaturesFrame(x_train).encode_label() #.add_feature_square().scale_standard() #.add_feature_interactions() #.add_feature_square() #.scale_standard(set=\"train\")\n",
    "test_test = FeaturesFrame(x_test).encode_label() #.add_feature_square().scale_standard(set='test', train_scaler=scaler) #.add_feature_interactions() #.add_feature_square() #.scale_standard(set=\"test\", train_scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = test_train.select('arret','encoded_gare')\n",
    "test_test = test_test.select('arret', 'encoded_gare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation - MSE: 4.3097, R2: 0.0675, MAE: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.30968257451896, 0.06750007177579564, 0.8515066898405728)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(model_enum=ModelEnum.XGBoost)\n",
    "model_fit = model.fit(test_train.to_numpy(), y_train=y_train.to_numpy())\n",
    "model.evaluate(X_test=test_test.to_numpy(), y_test=y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [00:00, 5820.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Model(model_enum=ModelEnum.XGBoost)\n",
    "params_opti_mlp = model.grid_search(test_train.to_pandas(), y_train=y_train.to_pandas(), param_grid = ParamGridEnum.XGBoost.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opti_xgb = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"max_depth\":5,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = XGBRegressor().set_params(**params_opti_xgb)\n",
    "mod_fit = mod.fit(test_train.to_numpy(),y_train.to_numpy())\n",
    "preds = mod.predict(X=test_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation - MSE: 4.2048, R2: 0.0902, MAE: 0.8183\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "mae = mean_absolute_error(y_test,preds)\n",
    "print(f\"Model Evaluation - MSE: {mse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EnumType.__call__() got an unexpected keyword argument 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_enum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mModelEnum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_opti_xgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m model_fit = model.fit(test_train.to_numpy(), y_train=y_train.to_numpy())\n\u001b[32m      3\u001b[39m model.evaluate(X_test=test_test.to_numpy(), y_test=y_test.to_numpy())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\faune\\challenge-data-203\\models.py:138\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model_enum, params)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m.model_enum = model_enum\n\u001b[32m    137\u001b[39m \u001b[38;5;28mself\u001b[39m.params = params\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minitialize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitialized model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.model_enum\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\faune\\challenge-data-203\\models.py:145\u001b[39m, in \u001b[36mModel.initialize_model\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._initialize_pytorch_model()\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_enum\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_enum.value()\n",
      "\u001b[31mTypeError\u001b[39m: EnumType.__call__() got an unexpected keyword argument 'n_estimators'"
     ]
    }
   ],
   "source": [
    "model = Model(model_enum=ModelEnum.XGBoost, params=params_opti_xgb)\n",
    "model_fit = model.fit(test_train.to_numpy(), y_train=y_train.to_numpy())\n",
    "model.evaluate(X_test=test_test.to_numpy(), y_test=y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(model_enum=ModelEnum.GradientBoosting)\n",
    "# params_opti_gb = model.optimize_parameters(test_train.to_pandas(), y_train=y_train.to_pandas(), param_grid = ParamGridEnum.GradientBoosting.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(model_enum=ModelEnum.SVR)\n",
    "# params_opti_svr = model.optimize_parameters(test_train.to_pandas(), y_train=y_train.to_pandas(), param_grid = ParamGridEnum.SVR.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(model_enum=ModelEnum.KNN)\n",
    "# params_opti_knn = model.optimize_parameters(test_train.to_pandas(), y_train=y_train.to_pandas(), param_grid = ParamGridEnum.KNN.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengedata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
