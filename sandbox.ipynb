{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Predicting SNCF wait times\n",
    "---\n",
    "In this notebook, we try to build a pipeline and framework in order to predict wait times for trains. \n",
    "\n",
    "We start by importing the data and splitting it. We then remove outliers and encoding categorical variables. \n",
    "\n",
    "Then, we perform hyperparameter optimization and train a simple XGBoost model accordingly. After this, we can export the results to make a submission on the challenge data website. \n",
    "\n",
    "Keep in mind that this notebook is only the tip of the iceberg : we have built libraries to preprocess features and test different models (they are accessible in the models.py and features.py modules). After trial and error, this is the best model that we can come up with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-05 23:06:30,911 - distributed.scheduler - WARNING - Worker failed to heartbeat for 2354s; attempting restart: <WorkerState 'tcp://127.0.0.1:51175', name: 3, status: running, memory: 0, processing: 0>\n",
      "2025-04-05 23:06:30,954 - distributed.scheduler - WARNING - Worker failed to heartbeat for 2354s; attempting restart: <WorkerState 'tcp://127.0.0.1:51178', name: 0, status: running, memory: 0, processing: 0>\n",
      "2025-04-05 23:06:30,956 - distributed.scheduler - WARNING - Worker failed to heartbeat for 2354s; attempting restart: <WorkerState 'tcp://127.0.0.1:51181', name: 2, status: running, memory: 0, processing: 0>\n",
      "2025-04-05 23:06:30,958 - distributed.scheduler - WARNING - Worker failed to heartbeat for 2354s; attempting restart: <WorkerState 'tcp://127.0.0.1:51184', name: 1, status: running, memory: 0, processing: 0>\n",
      "2025-04-05 23:06:32,482 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-04-05 23:06:32,503 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-04-05 23:06:32,512 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-04-05 23:06:32,654 - distributed.nanny - WARNING - Restarting worker\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "from utils import PathsData, import_data, split_data, plot_correlation\n",
    "from features import FeaturesFrame\n",
    "from models import Model, ModelEnum, ParamGridEnum\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "x_validation = import_data(PathsData.X_TEST.value) #! to use in the end to make a submission\n",
    "x = import_data(PathsData.X_TRAIN.value)\n",
    "y = import_data(PathsData.Y_TRAIN.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "After testing different methods, we have found that the one that yields the best results is simply based on a simple quantile exclusion.\n",
    "We have also tested different values to understand which is the best quantile to exclude. \n",
    "\n",
    "We start by visualizing the outliers with boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_plot = x.with_columns(y).select(cs.numeric())\n",
    "\n",
    "# fig = make_subplots(rows=3, cols=3, subplot_titles=[c for c in to_plot.columns])\n",
    "\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[0]).to_series().to_list()), boxpoints='all'), row=1, col=1)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[1]).to_series().to_list())), row=1, col=2)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[2]).to_series().to_list())), row=1, col=3)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[3]).to_series().to_list())), row=2, col=1)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[4]).to_series().to_list())), row=2, col=2)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[5]).to_series().to_list())), row=2, col=3)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[6]).to_series().to_list())), row=3, col=1)\n",
    "# fig.append_trace(go.Box(y=np.array(to_plot.select(to_plot.columns[7]).to_series().to_list())), row=3, col=2)\n",
    "\n",
    "# fig.update_layout(height=1000, width=1000, title_text=\"Outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#remove outliers:\n",
    "x = x.with_columns(y).filter(pl.col('p0q0').ge(pl.col('p0q0').quantile(0.05)) & pl.col('p0q0').le(pl.col('p0q0').quantile(0.95)))\n",
    "y = x.select('p0q0')\n",
    "x = x.drop('p0q0')\n",
    "\n",
    "x_train, x_test, y_train, y_test = split_data(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then encode the data using a frequency encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train = FeaturesFrame(x_train).encode_label(encoder='label').select(cs.numeric())#.add_feature_square().scale_standard() #.add_feature_interactions() #.add_feature_square() #.scale_standard(set=\"train\")\n",
    "test_test = FeaturesFrame(x_test).encode_label(encoder='label').select(cs.numeric()) #.add_feature_square().scale_standard(set='test', train_scaler=scaler) #.add_feature_interactions() #.add_feature_square() #.scale_standard(set=\"test\", train_scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run a first test with the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation - MSE: 0.5352, R2: 0.3688, MAE: 0.5525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5351877907598194, 0.3688269234678675, 0.5525199492175347)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(model_enum=ModelEnum.XGBoost)\n",
    "model_fit = model.fit(test_train.to_numpy(), y_train=y_train.to_numpy())\n",
    "model.evaluate(X_test=test_test.to_numpy(), y_test=y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we run a grid search to find the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    }
   ],
   "source": [
    "model = Model(model_enum=ModelEnum.XGBoost)\n",
    "params_opti_xgb = model.grid_search(test_train.to_pandas(), y_train=y_train.to_pandas(), param_grid = ParamGridEnum.XGBoost.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train our model again with these params and print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation - MSE: 0.5215, R2: 0.3850, MAE: 0.5430\n"
     ]
    }
   ],
   "source": [
    "mod = XGBRegressor().set_params(**params_opti_xgb)\n",
    "mod_fit = mod.fit(test_train.to_numpy(),y_train.to_numpy())\n",
    "preds = mod.predict(X=test_test.to_numpy())\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "r2 = r2_score(y_test, preds)\n",
    "mae = mean_absolute_error(y_test,preds)\n",
    "print(f\"Model Evaluation - MSE: {mse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(number: int, model: XGBRegressor):\n",
    "    predictions_validation = (\n",
    "        model\n",
    "        .predict(\n",
    "            FeaturesFrame(x_validation)\n",
    "            .encode_label(encoder='frequency')\n",
    "            .drop('train', 'gare', 'date').to_numpy()\n",
    "        )\n",
    "    )\n",
    "    (\n",
    "        pl.DataFrame(predictions_validation)\n",
    "        .rename({\"column_0\":\"y_test\"})\n",
    "        .with_row_index()\n",
    "        .write_csv(fr\"C:\\Users\\faune\\challenge-data-203\\submissions\\submission{number}.csv\", separator=\",\")\n",
    "    )\n",
    "    print(f\"Successfully saved submission number {number}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved submission number 9\n"
     ]
    }
   ],
   "source": [
    "make_submission(9, model=mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "challengedata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
